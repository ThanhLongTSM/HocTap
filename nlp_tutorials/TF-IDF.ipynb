{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fbb8dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "660981aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"Thor eating pizza, Loki is eating pizza, Ironman ate pizza already\",\n",
    "    \"Apple is announcing new iphone tomorrow\",\n",
    "    \"Tesla is announcing new model-3 tomorrow\",\n",
    "    \"Google is announcing new pixel-6 tomorrow\",\n",
    "    \"Microsoft is announcing new surface tomorrow\",\n",
    "    \"Amazon is announcing new eco-dot tomorrow\",\n",
    "    \"I am eating biryani and you are eating grapes\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4252c18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'thor': 25, 'eating': 10, 'pizza': 22, 'loki': 17, 'is': 16, 'ironman': 15, 'ate': 7, 'already': 0, 'apple': 5, 'announcing': 4, 'new': 20, 'iphone': 14, 'tomorrow': 26, 'tesla': 24, 'model': 19, 'google': 12, 'pixel': 21, 'microsoft': 18, 'surface': 23, 'amazon': 2, 'eco': 11, 'dot': 9, 'am': 1, 'biryani': 8, 'and': 3, 'you': 27, 'are': 6, 'grapes': 13}\n"
     ]
    }
   ],
   "source": [
    "v = TfidfVectorizer()\n",
    "tranformed_output = v.fit_transform(corpus)\n",
    "print(v.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d65b13a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_char_ngrams',\n",
       " '_char_wb_ngrams',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_check_params',\n",
       " '_check_stop_words_consistency',\n",
       " '_check_vocabulary',\n",
       " '_count_vocab',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_limit_features',\n",
       " '_more_tags',\n",
       " '_parameter_constraints',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_sort_features',\n",
       " '_stop_words_id',\n",
       " '_tfidf',\n",
       " '_validate_data',\n",
       " '_validate_ngram_range',\n",
       " '_validate_params',\n",
       " '_validate_vocabulary',\n",
       " '_warn_for_unused_params',\n",
       " '_white_spaces',\n",
       " '_word_ngrams',\n",
       " 'analyzer',\n",
       " 'binary',\n",
       " 'build_analyzer',\n",
       " 'build_preprocessor',\n",
       " 'build_tokenizer',\n",
       " 'decode',\n",
       " 'decode_error',\n",
       " 'dtype',\n",
       " 'encoding',\n",
       " 'fit',\n",
       " 'fit_transform',\n",
       " 'fixed_vocabulary_',\n",
       " 'get_feature_names_out',\n",
       " 'get_params',\n",
       " 'get_stop_words',\n",
       " 'idf_',\n",
       " 'input',\n",
       " 'inverse_transform',\n",
       " 'lowercase',\n",
       " 'max_df',\n",
       " 'max_features',\n",
       " 'min_df',\n",
       " 'ngram_range',\n",
       " 'norm',\n",
       " 'preprocessor',\n",
       " 'set_params',\n",
       " 'smooth_idf',\n",
       " 'stop_words',\n",
       " 'stop_words_',\n",
       " 'strip_accents',\n",
       " 'sublinear_tf',\n",
       " 'token_pattern',\n",
       " 'tokenizer',\n",
       " 'transform',\n",
       " 'use_idf',\n",
       " 'vocabulary',\n",
       " 'vocabulary_']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95bc3b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feature_names =  v.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "912a44aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already 2.386294361119891\n",
      "am 2.386294361119891\n",
      "amazon 2.386294361119891\n",
      "and 2.386294361119891\n",
      "announcing 1.2876820724517808\n",
      "apple 2.386294361119891\n",
      "are 2.386294361119891\n",
      "ate 2.386294361119891\n",
      "biryani 2.386294361119891\n",
      "dot 2.386294361119891\n",
      "eating 1.9808292530117262\n",
      "eco 2.386294361119891\n",
      "google 2.386294361119891\n",
      "grapes 2.386294361119891\n",
      "iphone 2.386294361119891\n",
      "ironman 2.386294361119891\n",
      "is 1.1335313926245225\n",
      "loki 2.386294361119891\n",
      "microsoft 2.386294361119891\n",
      "model 2.386294361119891\n",
      "new 1.2876820724517808\n",
      "pixel 2.386294361119891\n",
      "pizza 2.386294361119891\n",
      "surface 2.386294361119891\n",
      "tesla 2.386294361119891\n",
      "thor 2.386294361119891\n",
      "tomorrow 1.2876820724517808\n",
      "you 2.386294361119891\n"
     ]
    }
   ],
   "source": [
    "for word in all_feature_names:\n",
    "    indx = v.vocabulary_.get(word)\n",
    "    print(f\"{word} {v.idf_[indx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "545d8e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24266547, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.24266547, 0.        , 0.        ,\n",
       "        0.40286636, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.24266547, 0.11527033, 0.24266547, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.72799642, 0.        , 0.        ,\n",
       "        0.24266547, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.30652086,\n",
       "        0.5680354 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.5680354 ,\n",
       "        0.        , 0.26982671, 0.        , 0.        , 0.        ,\n",
       "        0.30652086, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.30652086, 0.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tranformed_output.toarray()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cda80126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./Data/ecommerceDataset.csv',header=None,names=['label','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b068927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample(df,label):\n",
    "    return df[df['label'] == label].sample(6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6a868130",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([create_sample(df,'Household'),create_sample(df,'Clothing & Accessories'),\n",
    "               create_sample(df,'Books'),create_sample(df,'Electronics')],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f9790b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Household                 6000\n",
       "Clothing & Accessories    6000\n",
       "Books                     6000\n",
       "Electronics               6000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "18ea6661",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label_num']=df.label.map({'Household':0,'Clothing & Accessories':1,'Books':2,'Electronics':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9e692711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(df.text,df.label_num,test_size = .2,random_state =0,stratify=df.label_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "77ec7704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train (19200,)\n",
      "Shape of X_test (4800,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X_train',X_train.shape)\n",
    "print('Shape of X_test',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1b265470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      1200\n",
      "           1       0.96      0.99      0.98      1200\n",
      "           2       0.96      0.95      0.96      1200\n",
      "           3       0.96      0.93      0.95      1200\n",
      "\n",
      "    accuracy                           0.95      4800\n",
      "   macro avg       0.95      0.95      0.95      4800\n",
      "weighted avg       0.95      0.95      0.95      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vectorize_tfidf',TfidfVectorizer()),\n",
    "    ('KNN',KNeighborsClassifier())\n",
    "])\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1569925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "61573081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    return ' '.join([token.lemma_ for token in doc if not token.is_punct and not token.is_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ca3af531",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_preprocess'] = df['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8f181756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93      1200\n",
      "           1       0.97      0.98      0.97      1200\n",
      "           2       0.95      0.95      0.95      1200\n",
      "           3       0.97      0.93      0.95      1200\n",
      "\n",
      "    accuracy                           0.95      4800\n",
      "   macro avg       0.95      0.95      0.95      4800\n",
      "weighted avg       0.95      0.95      0.95      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(df.text_preprocess,df.label_num,test_size = .2,random_state =0,stratify=df.label_num)\n",
    "clf = Pipeline([\n",
    "    ('vectorize_tfidf',TfidfVectorizer()),\n",
    "    ('KNN',KNeighborsClassifier())\n",
    "])\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658d728b",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2fbc67f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy         704\n",
       "sadness     550\n",
       "anger       275\n",
       "fear        212\n",
       "love        178\n",
       "surprise     81\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Data/Emotion dataset/val.txt',header = None,sep=';',names=['comment','emotion'])\n",
    "df.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5a605af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample1(df,label):\n",
    "    return df[df['emotion'] == label].sample(212)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9e007193",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([create_sample1(df,'fear'),create_sample1(df,'joy'),\n",
    "               create_sample1(df,'anger')],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fdc83a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emotion_num'] = df['emotion'].map({'fear':0,'joy':1,'anger':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "11ab929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preprocess_comment'] = df['comment'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "96faba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df.comment,df.emotion_num,test_size =.3,random_state = 0,stratify=df.emotion_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ac50eae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6a11fcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.44      0.57        64\n",
      "           1       0.44      0.88      0.59        64\n",
      "           2       0.80      0.38      0.52        63\n",
      "\n",
      "    accuracy                           0.57       191\n",
      "   macro avg       0.68      0.56      0.56       191\n",
      "weighted avg       0.68      0.57      0.56       191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('Vectorizer',CountVectorizer(ngram_range=(1,3))),\n",
    "    ('RandomForest',RandomForestClassifier())\n",
    "])\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "37737877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.67      0.68        64\n",
      "           1       0.69      0.48      0.57        64\n",
      "           2       0.61      0.81      0.69        63\n",
      "\n",
      "    accuracy                           0.65       191\n",
      "   macro avg       0.66      0.66      0.65       191\n",
      "weighted avg       0.66      0.65      0.65       191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('Vectorizer',CountVectorizer(ngram_range=(1,2))),\n",
    "    ('RandomForest',MultinomialNB())\n",
    "])\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3c3c7419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.61      0.62        64\n",
      "           1       0.67      0.44      0.53        64\n",
      "           2       0.57      0.79      0.67        63\n",
      "\n",
      "    accuracy                           0.61       191\n",
      "   macro avg       0.62      0.61      0.60       191\n",
      "weighted avg       0.62      0.61      0.60       191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('Vectorizer',CountVectorizer(ngram_range=(1,3))),\n",
    "    ('RandomForest',MultinomialNB())\n",
    "])\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e4b62fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.62      0.61        64\n",
      "           1       0.52      0.52      0.52        64\n",
      "           2       0.56      0.52      0.54        63\n",
      "\n",
      "    accuracy                           0.55       191\n",
      "   macro avg       0.55      0.55      0.55       191\n",
      "weighted avg       0.55      0.55      0.55       191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('Vectorizer',TfidfVectorizer()),\n",
    "    ('RandomForest',RandomForestClassifier())\n",
    "])\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7b994122",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df.preprocess_comment,df.emotion_num,test_size =.3,random_state = 0,stratify=df.emotion_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "10f22890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.62      0.68        64\n",
      "           1       0.51      0.75      0.61        64\n",
      "           2       0.77      0.54      0.64        63\n",
      "\n",
      "    accuracy                           0.64       191\n",
      "   macro avg       0.68      0.64      0.64       191\n",
      "weighted avg       0.68      0.64      0.64       191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('Vectorizer',TfidfVectorizer()),\n",
    "    ('RandomForest',RandomForestClassifier())\n",
    "])\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
