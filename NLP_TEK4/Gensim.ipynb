{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19ee66c6",
   "metadata": {},
   "source": [
    "### Gensim là gì?\n",
    "Gensim là một thư viện xử lý ngôn ngữ tự nhiên mã nguồn mở phổ biến. Nó sử dụng các mô hình học thuật hàng đầu để thực hiện các nhiệm vụ phức tạp như xây dựng các véc-tơ từ và thực hiện xác định chủ đề và so sánh tài liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "584fa81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1320b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = [\n",
    "   \"CNTK formerly known as Computational Network Toolkit\",\n",
    "   \"is a free easy-to-use open-source commercial-grade toolkit\",\n",
    "   \"that enable us to train deep learning algorithms to learn like the human brain.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc7196c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cntk', 'formerly', 'known', 'as', 'computational', 'network', 'toolkit'],\n",
       " ['is',\n",
       "  'a',\n",
       "  'free',\n",
       "  'easy-to-use',\n",
       "  'open-source',\n",
       "  'commercial-grade',\n",
       "  'toolkit'],\n",
       " ['that',\n",
       "  'enable',\n",
       "  'us',\n",
       "  'to',\n",
       "  'train',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'algorithms',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'like',\n",
       "  'the',\n",
       "  'human',\n",
       "  'brain',\n",
       "  '.']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_docs = [word_tokenize((doc.lower())) for doc in doc]\n",
    "tokenized_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9fbd714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(tokenized_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91faafd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'as': 0,\n",
       " 'cntk': 1,\n",
       " 'computational': 2,\n",
       " 'formerly': 3,\n",
       " 'known': 4,\n",
       " 'network': 5,\n",
       " 'toolkit': 6,\n",
       " 'a': 7,\n",
       " 'commercial-grade': 8,\n",
       " 'easy-to-use': 9,\n",
       " 'free': 10,\n",
       " 'is': 11,\n",
       " 'open-source': 12,\n",
       " '.': 13,\n",
       " 'algorithms': 14,\n",
       " 'brain': 15,\n",
       " 'deep': 16,\n",
       " 'enable': 17,\n",
       " 'human': 18,\n",
       " 'learn': 19,\n",
       " 'learning': 20,\n",
       " 'like': 21,\n",
       " 'that': 22,\n",
       " 'the': 23,\n",
       " 'to': 24,\n",
       " 'train': 25,\n",
       " 'us': 26}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Danh sách tất cả các token và id tương ứng của chúng trong danh sách từ điển mới\n",
    "dictionary.token2id "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7182da",
   "metadata": {},
   "source": [
    "##### Tạo một corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e4ded75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)],\n",
       " [(6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)],\n",
       " [(13, 1),\n",
       "  (14, 1),\n",
       "  (15, 1),\n",
       "  (16, 1),\n",
       "  (17, 1),\n",
       "  (18, 1),\n",
       "  (19, 1),\n",
       "  (20, 1),\n",
       "  (21, 1),\n",
       "  (22, 1),\n",
       "  (23, 1),\n",
       "  (24, 2),\n",
       "  (25, 1),\n",
       "  (26, 1)]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]\n",
    "corpus\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae874231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cntk', 'formerly', 'known', 'as', 'computational', 'network', 'toolkit']\n",
      "['is', 'a', 'free', 'easy-to-use', 'open-source', 'commercial-grade', 'toolkit']\n",
      "['that', 'enable', 'us', 'to', 'train', 'deep', 'learning', 'algorithms', 'to', 'learn', 'like', 'the', 'human', 'brain', '.']\n"
     ]
    }
   ],
   "source": [
    "c = [print(doc) for doc in tokenized_docs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199e6fcc",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd6dd5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = [\n",
    "   'CNTK formerly known as Computational Network Toolkit',\n",
    "   \"is a free easy-to-use open-source commercial-grade toolkit\",\n",
    "   \"that enable us to train deep learning algorithms to learn like the human brain.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75f2379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7072afe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cntk', 'formerly', 'known', 'as', 'computational', 'network', 'toolkit'],\n",
       " ['is',\n",
       "  'a',\n",
       "  'free',\n",
       "  'easy-to-use',\n",
       "  'open-source',\n",
       "  'commercial-grade',\n",
       "  'toolkit'],\n",
       " ['that',\n",
       "  'enable',\n",
       "  'us',\n",
       "  'to',\n",
       "  'train',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'algorithms',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'like',\n",
       "  'the',\n",
       "  'human',\n",
       "  'brain',\n",
       "  '.']]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = [word_tokenize(doc.lower()) for doc in doc]\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c991f878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'as': 0,\n",
       " 'cntk': 1,\n",
       " 'computational': 2,\n",
       " 'formerly': 3,\n",
       " 'known': 4,\n",
       " 'network': 5,\n",
       " 'toolkit': 6,\n",
       " 'a': 7,\n",
       " 'commercial-grade': 8,\n",
       " 'easy-to-use': 9,\n",
       " 'free': 10,\n",
       " 'is': 11,\n",
       " 'open-source': 12,\n",
       " '.': 13,\n",
       " 'algorithms': 14,\n",
       " 'brain': 15,\n",
       " 'deep': 16,\n",
       " 'enable': 17,\n",
       " 'human': 18,\n",
       " 'learn': 19,\n",
       " 'learning': 20,\n",
       " 'like': 21,\n",
       " 'that': 22,\n",
       " 'the': 23,\n",
       " 'to': 24,\n",
       " 'train': 25,\n",
       " 'us': 26}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diction = Dictionary(articles)\n",
    "diction.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1c147aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diction.token2id.get('deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b69d81d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6, 1)]\n"
     ]
    }
   ],
   "source": [
    "MnCorpus=[diction.doc2bow(doc) for doc in tokens]\n",
    "print(MnCorpus[1][:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f8d9d2",
   "metadata": {},
   "source": [
    "### Gensim bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ddbd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
